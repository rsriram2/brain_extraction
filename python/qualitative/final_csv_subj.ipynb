{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d174f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcdf9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing method: CTBET\n",
      "Excluding 2 files from CTBET\n",
      "Available failure columns for CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Processing method: Robust-CTBET\n",
      "Excluding 0 files from Robust-CTBET\n",
      "Available failure columns for Robust-CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Processing method: SynthStrip\n",
      "Excluding 40 files from SynthStrip\n",
      "Available failure columns for SynthStrip: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Processing method: HD-CTBET\n",
      "Excluding 15 files from HD-CTBET\n",
      "Available failure columns for HD-CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Processing method: CT_BET\n",
      "Excluding 5 files from CT_BET\n",
      "Available failure columns for CT_BET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Processing method: Brainchop\n",
      "Filtered out 7 files from brainchop\n",
      "Excluding 5 files from Brainchop\n",
      "Available failure columns for Brainchop: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Processing method: CTbet_Docker\n",
      "Filtered out 7 files from dockerctbet\n",
      "Excluding 3 files from CTbet_Docker\n",
      "Available failure columns for CTbet_Docker: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Results saved to CSV file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Total_Count</th>\n",
       "      <th>Total_Failure_Count</th>\n",
       "      <th>Total_Failure_Rate</th>\n",
       "      <th>Volumetrics_Count</th>\n",
       "      <th>Volumetrics_Rate</th>\n",
       "      <th>Registration_Count</th>\n",
       "      <th>Registration_Rate</th>\n",
       "      <th>DL_Count</th>\n",
       "      <th>DL_Rate</th>\n",
       "      <th>Multiple_Failures_Count</th>\n",
       "      <th>Multiple_Failures_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTBET</td>\n",
       "      <td>499</td>\n",
       "      <td>169</td>\n",
       "      <td>33.867735</td>\n",
       "      <td>168</td>\n",
       "      <td>33.667335</td>\n",
       "      <td>118</td>\n",
       "      <td>23.647295</td>\n",
       "      <td>126</td>\n",
       "      <td>25.250501</td>\n",
       "      <td>126</td>\n",
       "      <td>25.250501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robust-CTBET</td>\n",
       "      <td>499</td>\n",
       "      <td>14</td>\n",
       "      <td>2.805611</td>\n",
       "      <td>14</td>\n",
       "      <td>2.805611</td>\n",
       "      <td>8</td>\n",
       "      <td>1.603206</td>\n",
       "      <td>9</td>\n",
       "      <td>1.803607</td>\n",
       "      <td>9</td>\n",
       "      <td>1.803607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynthStrip</td>\n",
       "      <td>499</td>\n",
       "      <td>308</td>\n",
       "      <td>61.723447</td>\n",
       "      <td>307</td>\n",
       "      <td>61.523046</td>\n",
       "      <td>136</td>\n",
       "      <td>27.254509</td>\n",
       "      <td>182</td>\n",
       "      <td>36.472946</td>\n",
       "      <td>190</td>\n",
       "      <td>38.076152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD-CTBET</td>\n",
       "      <td>499</td>\n",
       "      <td>105</td>\n",
       "      <td>21.042084</td>\n",
       "      <td>105</td>\n",
       "      <td>21.042084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT_BET</td>\n",
       "      <td>461</td>\n",
       "      <td>315</td>\n",
       "      <td>68.329718</td>\n",
       "      <td>314</td>\n",
       "      <td>68.112798</td>\n",
       "      <td>249</td>\n",
       "      <td>54.013015</td>\n",
       "      <td>126</td>\n",
       "      <td>27.331887</td>\n",
       "      <td>271</td>\n",
       "      <td>58.785249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brainchop</td>\n",
       "      <td>499</td>\n",
       "      <td>222</td>\n",
       "      <td>44.488978</td>\n",
       "      <td>222</td>\n",
       "      <td>44.488978</td>\n",
       "      <td>167</td>\n",
       "      <td>33.466934</td>\n",
       "      <td>60</td>\n",
       "      <td>12.024048</td>\n",
       "      <td>167</td>\n",
       "      <td>33.466934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTbet_Docker</td>\n",
       "      <td>499</td>\n",
       "      <td>52</td>\n",
       "      <td>10.420842</td>\n",
       "      <td>52</td>\n",
       "      <td>10.420842</td>\n",
       "      <td>22</td>\n",
       "      <td>4.408818</td>\n",
       "      <td>28</td>\n",
       "      <td>5.611222</td>\n",
       "      <td>38</td>\n",
       "      <td>7.615230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Method  Total_Count  Total_Failure_Count  Total_Failure_Rate  \\\n",
       "0         CTBET          499                  169           33.867735   \n",
       "1  Robust-CTBET          499                   14            2.805611   \n",
       "2    SynthStrip          499                  308           61.723447   \n",
       "3      HD-CTBET          499                  105           21.042084   \n",
       "4        CT_BET          461                  315           68.329718   \n",
       "5     Brainchop          499                  222           44.488978   \n",
       "6  CTbet_Docker          499                   52           10.420842   \n",
       "\n",
       "   Volumetrics_Count  Volumetrics_Rate  Registration_Count  Registration_Rate  \\\n",
       "0                168         33.667335                 118          23.647295   \n",
       "1                 14          2.805611                   8           1.603206   \n",
       "2                307         61.523046                 136          27.254509   \n",
       "3                105         21.042084                   0           0.000000   \n",
       "4                314         68.112798                 249          54.013015   \n",
       "5                222         44.488978                 167          33.466934   \n",
       "6                 52         10.420842                  22           4.408818   \n",
       "\n",
       "   DL_Count    DL_Rate  Multiple_Failures_Count  Multiple_Failures_Rate  \n",
       "0       126  25.250501                      126               25.250501  \n",
       "1         9   1.803607                        9                1.803607  \n",
       "2       182  36.472946                      190               38.076152  \n",
       "3         0   0.000000                        0                0.000000  \n",
       "4       126  27.331887                      271               58.785249  \n",
       "5        60  12.024048                      167               33.466934  \n",
       "6        28   5.611222                       38                7.615230  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = ['CTBET', 'Robust-CTBET', 'SynthStrip', 'HD-CTBET', 'CT_BET', 'Brainchop', 'CTbet_Docker']\n",
    "exclude_prefixes = (\"6046\", \"6084\", \"6096\", \"6246\", \"6315\", \"6342\", \"6499\")\n",
    "\n",
    "brainchop_exclude = ['6109-317_20150302_0647_ct.png', '6142-308_20150610_0707_ct.png', '6193-324_20150924_1431_ct.png', '6257-335_20160118_1150_ct.png',\n",
    "                     '6418-193_20161228_1248_ct.png', '6470-296_20170602_0607_ct.png', '6480-154_20170622_0937_ct.png']\n",
    "\n",
    "dockerctbet_exclude = ['6109-317_20150302_0647_ct.png', '6142-308_20150610_0707_ct.png', '6193-324_20150924_1431_ct.png', '6257-335_20160118_1150_ct.png',\n",
    "                       '6418-193_20161228_1248_ct.png', '6470-296_20170602_0607_ct.png', '6480-154_20170622_0937_ct.png']\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"Processing method: {method}\")\n",
    "    # Read the single CSV file with the new columns\n",
    "    csv_file = pd.read_csv(f'/Users/rushil/brain_extraction/data/qc/{method}/{method}_final_v2.csv')\n",
    "    if method == 'Brainchop':\n",
    "        csv_file = csv_file[~csv_file['Filename'].isin(brainchop_exclude)]\n",
    "        print(f\"Filtered out {len(brainchop_exclude)} files from brainchop\")\n",
    "        \n",
    "    if method == 'CTbet_Docker':\n",
    "        csv_file = csv_file[~csv_file['Filename'].isin(dockerctbet_exclude)]\n",
    "        print(f\"Filtered out {len(dockerctbet_exclude)} files from dockerctbet\")    \n",
    "\n",
    "    \n",
    "    # Apply exclusions based on filename prefixes\n",
    "    csv_file[\"basename\"] = csv_file[\"Filename\"].str.split(\"/\").str[-1]\n",
    "\n",
    "    # Apply exclusions on the basename\n",
    "    mask = ~csv_file[\"basename\"].str.startswith(exclude_prefixes)\n",
    "    print(f\"Excluding {len(csv_file) - mask.sum()} files from {method}\")\n",
    "    csv_file = csv_file[mask]\n",
    "            \n",
    "    # Define the failure columns to check\n",
    "    failure_columns = ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
    "    available_columns = [col for col in failure_columns if col in csv_file.columns]\n",
    "    print(f\"Available failure columns for {method}: {available_columns}\")\n",
    "    \n",
    "    if method != 'CT_BET':\n",
    "        total_count = 499\n",
    "    else:\n",
    "        total_count = 461\n",
    "        \n",
    "    csv_file['Subject_ID'] = csv_file['Filename'].apply(lambda x: x.split('_')[0])\n",
    "    csv_file['Scan_Date'] = csv_file['Filename'].apply(lambda x: x.split('_')[1])\n",
    "    csv_file['Scan_Time'] = csv_file['Filename'].apply(lambda x: x.split('_')[2])\n",
    "    csv_file = csv_file.groupby('Subject_ID').agg({\n",
    "        '1 - Volumetrics': lambda x: 'yes' if 'yes' in x.values else 'no',\n",
    "        '2 - Registration': lambda x: 'yes' if 'yes' in x.values else 'no',\n",
    "        '3 - DL': lambda x: 'yes' if 'yes' in x.values else 'no'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Count failures for each individual column\n",
    "    volumetrics_count = len(csv_file[csv_file['1 - Volumetrics'] == 'yes']) if '1 - Volumetrics' in available_columns else 0\n",
    "    registration_count = len(csv_file[csv_file['2 - Registration'] == 'yes']) if '2 - Registration' in available_columns else 0\n",
    "    dl_count = len(csv_file[csv_file['3 - DL'] == 'yes']) if '3 - DL' in available_columns else 0\n",
    "    \n",
    "    # Count total failures (any failure in any column)\n",
    "    total_failures_count = len(csv_file[csv_file[available_columns].eq('yes').any(axis=1)]) if available_columns else 0\n",
    "    \n",
    "    # Count multiple failures (failures in 2 or more columns)\n",
    "    yes_counts_per_row = csv_file[available_columns].eq('yes').sum(axis=1) if available_columns else pd.Series([0] * len(csv_file))\n",
    "    multiple_failures_count = len(csv_file[yes_counts_per_row >= 2])\n",
    "    \n",
    "    # Create results dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Method': [method],\n",
    "        'Total_Count': total_count,\n",
    "        'Total_Failure_Count': [total_failures_count],\n",
    "        'Total_Failure_Rate': [total_failures_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Volumetrics_Count': [volumetrics_count],\n",
    "        'Volumetrics_Rate': [volumetrics_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Registration_Count': [registration_count],\n",
    "        'Registration_Rate': [registration_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'DL_Count': [dl_count],\n",
    "        'DL_Rate': [dl_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Multiple_Failures_Count': [multiple_failures_count],\n",
    "        'Multiple_Failures_Rate': [multiple_failures_count / total_count * 100 if total_count > 0 else 0]\n",
    "    })\n",
    "    \n",
    "    all_results.append(df)\n",
    "\n",
    "# Combine all results\n",
    "final_results = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Define column order\n",
    "column_order = [\n",
    "    \"Method\",\n",
    "    \"Total_Count\",\n",
    "    \"Total_Failure_Count\", \"Total_Failure_Rate\",\n",
    "    \"Volumetrics_Count\", \"Volumetrics_Rate\",\n",
    "    \"Registration_Count\", \"Registration_Rate\",\n",
    "    \"DL_Count\", \"DL_Rate\",\n",
    "    \"Multiple_Failures_Count\", \"Multiple_Failures_Rate\"\n",
    "]\n",
    "\n",
    "final_results = final_results[column_order]\n",
    "final_results.to_csv('/Users/rushil/brain_extraction/results/qualitative/subj_lvl/Rushil_QC_subj_results.csv', index=False)\n",
    "print(\"Results saved to CSV file\")\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d40adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing craniotomy subject-level results for method: CTBET\n",
      "Found 7 craniotomy scans for CTBET\n",
      "Available failure columns for CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 6 unique subjects with craniotomy for CTBET\n",
      "Processing craniotomy subject-level results for method: Robust-CTBET\n",
      "Found 0 craniotomy scans for Robust-CTBET\n",
      "Available failure columns for Robust-CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 0 unique subjects with craniotomy for Robust-CTBET\n",
      "Processing craniotomy subject-level results for method: SynthStrip\n",
      "Found 31 craniotomy scans for SynthStrip\n",
      "Available failure columns for SynthStrip: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 10 unique subjects with craniotomy for SynthStrip\n",
      "Processing craniotomy subject-level results for method: HD-CTBET\n",
      "Found 10 craniotomy scans for HD-CTBET\n",
      "Available failure columns for HD-CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 5 unique subjects with craniotomy for HD-CTBET\n",
      "Processing craniotomy subject-level results for method: CT_BET\n",
      "Found 18 craniotomy scans for CT_BET\n",
      "Available failure columns for CT_BET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 6 unique subjects with craniotomy for CT_BET\n",
      "Processing craniotomy subject-level results for method: Brainchop\n",
      "Filtered out 7 files from brainchop\n",
      "Found 9 craniotomy scans for Brainchop\n",
      "Available failure columns for Brainchop: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 5 unique subjects with craniotomy for Brainchop\n",
      "Processing craniotomy subject-level results for method: CTbet_Docker\n",
      "Filtered out 7 files from dockerctbet\n",
      "Found 14 craniotomy scans for CTbet_Docker\n",
      "Available failure columns for CTbet_Docker: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 7 unique subjects with craniotomy for CTbet_Docker\n",
      "Craniotomy subject-level results saved to CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Subject_ID'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Date'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Time'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Subject_ID'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Date'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Time'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Subject_ID'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Date'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Time'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Subject_ID'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Date'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Time'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Subject_ID'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Date'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Time'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Subject_ID'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Date'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2244138163.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  craniotomy_cases['Scan_Time'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[2])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Total_Count</th>\n",
       "      <th>Total_Failure_Count</th>\n",
       "      <th>Total_Failure_Rate</th>\n",
       "      <th>Volumetrics_Count</th>\n",
       "      <th>Volumetrics_Rate</th>\n",
       "      <th>Registration_Count</th>\n",
       "      <th>Registration_Rate</th>\n",
       "      <th>DL_Count</th>\n",
       "      <th>DL_Rate</th>\n",
       "      <th>Multiple_Failures_Count</th>\n",
       "      <th>Multiple_Failures_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTBET</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>4</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>2</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>2</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>3</td>\n",
       "      <td>21.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robust-CTBET</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynthStrip</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>5</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>6</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD-CTBET</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT_BET</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>6</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>4</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>6</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>6</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brainchop</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>2</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTbet_Docker</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Method  Total_Count  Total_Failure_Count  Total_Failure_Rate  \\\n",
       "0         CTBET           14                    4           28.571429   \n",
       "1  Robust-CTBET           14                    0            0.000000   \n",
       "2    SynthStrip           14                    7           50.000000   \n",
       "3      HD-CTBET           14                    0            0.000000   \n",
       "4        CT_BET            7                    6           85.714286   \n",
       "5     Brainchop           14                    2           14.285714   \n",
       "6  CTbet_Docker           14                    1            7.142857   \n",
       "\n",
       "   Volumetrics_Count  Volumetrics_Rate  Registration_Count  Registration_Rate  \\\n",
       "0                  4         28.571429                   2          14.285714   \n",
       "1                  0          0.000000                   0           0.000000   \n",
       "2                  7         50.000000                   4          28.571429   \n",
       "3                  0          0.000000                   0           0.000000   \n",
       "4                  6         85.714286                   4          57.142857   \n",
       "5                  2         14.285714                   1           7.142857   \n",
       "6                  1          7.142857                   0           0.000000   \n",
       "\n",
       "   DL_Count    DL_Rate  Multiple_Failures_Count  Multiple_Failures_Rate  \n",
       "0         2  14.285714                        3               21.428571  \n",
       "1         0   0.000000                        0                0.000000  \n",
       "2         5  35.714286                        6               42.857143  \n",
       "3         0   0.000000                        0                0.000000  \n",
       "4         6  85.714286                        6               85.714286  \n",
       "5         0   0.000000                        1                7.142857  \n",
       "6         0   0.000000                        0                0.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Craniotomy Subject-Level Analysis\n",
    "methods = ['CTBET', 'Robust-CTBET', 'SynthStrip', 'HD-CTBET', 'CT_BET', 'Brainchop', 'CTbet_Docker']\n",
    "exclude_prefixes = (\"6046\", \"6084\", \"6096\", \"6246\", \"6315\", \"6342\", \"6499\")\n",
    "\n",
    "brainchop_exclude = ['6109-317_20150302_0647_ct.png', '6142-308_20150610_0707_ct.png', '6193-324_20150924_1431_ct.png', '6257-335_20160118_1150_ct.png',\n",
    "                     '6418-193_20161228_1248_ct.png', '6470-296_20170602_0607_ct.png', '6480-154_20170622_0937_ct.png']\n",
    "\n",
    "dockerctbet_exclude = ['6109-317_20150302_0647_ct.png', '6142-308_20150610_0707_ct.png', '6193-324_20150924_1431_ct.png', '6257-335_20160118_1150_ct.png',\n",
    "                       '6418-193_20161228_1248_ct.png', '6470-296_20170602_0607_ct.png', '6480-154_20170622_0937_ct.png']\n",
    "\n",
    "craniotomy_results = []\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"Processing craniotomy subject-level results for method: {method}\")\n",
    "    # Read the CSV file with the new columns\n",
    "    csv_file = pd.read_csv(f'/Users/rushil/brain_extraction/data/qc/{method}/{method}_final_v2.csv')\n",
    "    \n",
    "    if method == 'Brainchop':\n",
    "        csv_file = csv_file[~csv_file['Filename'].isin(brainchop_exclude)]\n",
    "        print(f\"Filtered out {len(brainchop_exclude)} files from brainchop\")\n",
    "        \n",
    "    if method == 'CTbet_Docker':\n",
    "        csv_file = csv_file[~csv_file['Filename'].isin(dockerctbet_exclude)]\n",
    "        print(f\"Filtered out {len(dockerctbet_exclude)} files from dockerctbet\")    \n",
    "\n",
    "    # Apply exclusions based on filename prefixes\n",
    "    mask = ~csv_file['Filename'].str.startswith(exclude_prefixes)\n",
    "    csv_file = csv_file[mask]\n",
    "    \n",
    "    # Filter for craniotomy cases only\n",
    "    craniotomy_cases = csv_file[csv_file['craniotomy'] == 1]\n",
    "    print(f\"Found {len(craniotomy_cases)} craniotomy scans for {method}\")\n",
    "    \n",
    "    # Define the failure columns to check\n",
    "    failure_columns = ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
    "    available_columns = [col for col in failure_columns if col in craniotomy_cases.columns]\n",
    "    print(f\"Available failure columns for {method}: {available_columns}\")\n",
    "    \n",
    "    # Set total count based on method (subject-level counts)\n",
    "    if method != 'CT_BET':\n",
    "        total_count = 14  # Total subjects with craniotomy\n",
    "    else:\n",
    "        total_count = 7   # Total subjects with craniotomy for ctbet\n",
    "    \n",
    "    # Extract subject information and aggregate at subject level\n",
    "    craniotomy_cases['Subject_ID'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
    "    craniotomy_cases['Scan_Date'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
    "    craniotomy_cases['Scan_Time'] = craniotomy_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
    "    \n",
    "    # Group by subject and aggregate (if any scan for a subject has failure, subject has failure)\n",
    "    craniotomy_subj = craniotomy_cases.groupby('Subject_ID').agg({\n",
    "        '1 - Volumetrics': lambda x: 'yes' if 'yes' in x.values else 'no',\n",
    "        '2 - Registration': lambda x: 'yes' if 'yes' in x.values else 'no',\n",
    "        '3 - DL': lambda x: 'yes' if 'yes' in x.values else 'no'\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(f\"Found {len(craniotomy_subj)} unique subjects with craniotomy for {method}\")\n",
    "    \n",
    "    # Count failures for each individual column\n",
    "    volumetrics_count = len(craniotomy_subj[craniotomy_subj['1 - Volumetrics'] == 'yes']) if '1 - Volumetrics' in available_columns else 0\n",
    "    registration_count = len(craniotomy_subj[craniotomy_subj['2 - Registration'] == 'yes']) if '2 - Registration' in available_columns else 0\n",
    "    dl_count = len(craniotomy_subj[craniotomy_subj['3 - DL'] == 'yes']) if '3 - DL' in available_columns else 0\n",
    "    \n",
    "    # Count total failures (any failure in any column)\n",
    "    total_failures_count = len(craniotomy_subj[craniotomy_subj[available_columns].eq('yes').any(axis=1)]) if available_columns else 0\n",
    "    \n",
    "    # Count multiple failures (failures in 2 or more columns)\n",
    "    yes_counts_per_row = craniotomy_subj[available_columns].eq('yes').sum(axis=1) if available_columns else pd.Series([0] * len(craniotomy_subj))\n",
    "    multiple_failures_count = len(craniotomy_subj[yes_counts_per_row >= 2])\n",
    "    \n",
    "    # Create results dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Method': [method],\n",
    "        'Total_Count': [total_count],\n",
    "        'Total_Failure_Count': [total_failures_count],\n",
    "        'Total_Failure_Rate': [total_failures_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Volumetrics_Count': [volumetrics_count],\n",
    "        'Volumetrics_Rate': [volumetrics_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Registration_Count': [registration_count],\n",
    "        'Registration_Rate': [registration_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'DL_Count': [dl_count],\n",
    "        'DL_Rate': [dl_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Multiple_Failures_Count': [multiple_failures_count],\n",
    "        'Multiple_Failures_Rate': [multiple_failures_count / total_count * 100 if total_count > 0 else 0]\n",
    "    })\n",
    "    \n",
    "    craniotomy_results.append(df)\n",
    "\n",
    "# Combine all craniotomy results\n",
    "final_craniotomy_results = pd.concat(craniotomy_results, ignore_index=True)\n",
    "\n",
    "# Define column order\n",
    "column_order = [\n",
    "    \"Method\",\n",
    "    \"Total_Count\",\n",
    "    \"Total_Failure_Count\", \"Total_Failure_Rate\",\n",
    "    \"Volumetrics_Count\", \"Volumetrics_Rate\",\n",
    "    \"Registration_Count\", \"Registration_Rate\",\n",
    "    \"DL_Count\", \"DL_Rate\",\n",
    "    \"Multiple_Failures_Count\", \"Multiple_Failures_Rate\"\n",
    "]\n",
    "\n",
    "final_craniotomy_results = final_craniotomy_results[column_order]\n",
    "final_craniotomy_results.to_csv('/Users/rushil/brain_extraction/results/qualitative/subj_lvl/Rushil_QC_craniotomy_subj_results.csv', index=False)\n",
    "print(\"Craniotomy subject-level results saved to CSV file\")\n",
    "final_craniotomy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e0a89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CTA subject-level results for method: CTBET\n",
      "Found 3 CTA scans for CTBET\n",
      "Available failure columns for CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 3 unique subjects with CTA for CTBET\n",
      "Processing CTA subject-level results for method: Robust-CTBET\n",
      "Found 0 CTA scans for Robust-CTBET\n",
      "Available failure columns for Robust-CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 0 unique subjects with CTA for Robust-CTBET\n",
      "Processing CTA subject-level results for method: SynthStrip\n",
      "Found 4 CTA scans for SynthStrip\n",
      "Available failure columns for SynthStrip: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 4 unique subjects with CTA for SynthStrip\n",
      "Processing CTA subject-level results for method: HD-CTBET\n",
      "Found 1 CTA scans for HD-CTBET\n",
      "Available failure columns for HD-CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 1 unique subjects with CTA for HD-CTBET\n",
      "Processing CTA subject-level results for method: CT_BET\n",
      "Found 6 CTA scans for CT_BET\n",
      "Available failure columns for CT_BET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 6 unique subjects with CTA for CT_BET\n",
      "Processing CTA subject-level results for method: Brainchop\n",
      "Filtered out 7 files from brainchop\n",
      "Found 2 CTA scans for Brainchop\n",
      "Available failure columns for Brainchop: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 2 unique subjects with CTA for Brainchop\n",
      "Processing CTA subject-level results for method: CTbet_Docker\n",
      "Filtered out 7 files from dockerctbet\n",
      "Found 1 CTA scans for CTbet_Docker\n",
      "Available failure columns for CTbet_Docker: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 1 unique subjects with CTA for CTbet_Docker\n",
      "CTA subject-level results saved to CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Subject_ID'] = cta_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Date'] = cta_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Time'] = cta_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Subject_ID'] = cta_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Date'] = cta_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Time'] = cta_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Subject_ID'] = cta_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Date'] = cta_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Time'] = cta_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Subject_ID'] = cta_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Date'] = cta_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Time'] = cta_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Subject_ID'] = cta_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Date'] = cta_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Time'] = cta_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Subject_ID'] = cta_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Date'] = cta_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2721913547.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cta_cases['Scan_Time'] = cta_cases['Filename'].apply(lambda x: x.split('_')[2])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Total_Count</th>\n",
       "      <th>Total_Failure_Count</th>\n",
       "      <th>Total_Failure_Rate</th>\n",
       "      <th>Volumetrics_Count</th>\n",
       "      <th>Volumetrics_Rate</th>\n",
       "      <th>Registration_Count</th>\n",
       "      <th>Registration_Rate</th>\n",
       "      <th>DL_Count</th>\n",
       "      <th>DL_Rate</th>\n",
       "      <th>Multiple_Failures_Count</th>\n",
       "      <th>Multiple_Failures_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTBET</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robust-CTBET</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynthStrip</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD-CTBET</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT_BET</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>5</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>2</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>3</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brainchop</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTbet_Docker</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Method  Total_Count  Total_Failure_Count  Total_Failure_Rate  \\\n",
       "0         CTBET           10                    3           30.000000   \n",
       "1  Robust-CTBET           10                    0            0.000000   \n",
       "2    SynthStrip           10                    0            0.000000   \n",
       "3      HD-CTBET           10                    0            0.000000   \n",
       "4        CT_BET            7                    5           71.428571   \n",
       "5     Brainchop           10                    1           10.000000   \n",
       "6  CTbet_Docker           10                    0            0.000000   \n",
       "\n",
       "   Volumetrics_Count  Volumetrics_Rate  Registration_Count  Registration_Rate  \\\n",
       "0                  3         30.000000                   2          20.000000   \n",
       "1                  0          0.000000                   0           0.000000   \n",
       "2                  0          0.000000                   0           0.000000   \n",
       "3                  0          0.000000                   0           0.000000   \n",
       "4                  5         71.428571                   2          28.571429   \n",
       "5                  1         10.000000                   0           0.000000   \n",
       "6                  0          0.000000                   0           0.000000   \n",
       "\n",
       "   DL_Count    DL_Rate  Multiple_Failures_Count  Multiple_Failures_Rate  \n",
       "0         2  20.000000                        2               20.000000  \n",
       "1         0   0.000000                        0                0.000000  \n",
       "2         0   0.000000                        0                0.000000  \n",
       "3         0   0.000000                        0                0.000000  \n",
       "4         2  28.571429                        3               42.857143  \n",
       "5         0   0.000000                        0                0.000000  \n",
       "6         0   0.000000                        0                0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CTA Subject-Level Analysis\n",
    "cta_results = []\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"Processing CTA subject-level results for method: {method}\")\n",
    "    # Read the CSV file with the new columns\n",
    "    csv_file = pd.read_csv(f'/Users/rushil/brain_extraction/data/qc/{method}/{method}_final_v2.csv')\n",
    "    \n",
    "    if method == 'Brainchop':\n",
    "        csv_file = csv_file[~csv_file['Filename'].isin(brainchop_exclude)]\n",
    "        print(f\"Filtered out {len(brainchop_exclude)} files from brainchop\")\n",
    "        \n",
    "    if method == 'CTbet_Docker':\n",
    "        csv_file = csv_file[~csv_file['Filename'].isin(dockerctbet_exclude)]\n",
    "        print(f\"Filtered out {len(dockerctbet_exclude)} files from dockerctbet\")    \n",
    "\n",
    "    # Apply exclusions based on filename prefixes\n",
    "    mask = ~csv_file['Filename'].str.startswith(exclude_prefixes)\n",
    "    csv_file = csv_file[mask]\n",
    "    \n",
    "    # Filter for CTA cases only\n",
    "    cta_cases = csv_file[csv_file['cta'] == 1]\n",
    "    print(f\"Found {len(cta_cases)} CTA scans for {method}\")\n",
    "    \n",
    "    # Define the failure columns to check\n",
    "    failure_columns = ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
    "    available_columns = [col for col in failure_columns if col in cta_cases.columns]\n",
    "    print(f\"Available failure columns for {method}: {available_columns}\")\n",
    "    \n",
    "    # Set total count based on method (subject-level counts)\n",
    "    if method != 'CT_BET':\n",
    "        total_count = 10  # Total subjects with CTA\n",
    "    else:\n",
    "        total_count = 7   # Total subjects with CTA for ctbet\n",
    "    \n",
    "    # Extract subject information and aggregate at subject level\n",
    "    cta_cases['Subject_ID'] = cta_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
    "    cta_cases['Scan_Date'] = cta_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
    "    cta_cases['Scan_Time'] = cta_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
    "    \n",
    "    # Group by subject and aggregate (if any scan for a subject has failure, subject has failure)\n",
    "    cta_subj = cta_cases.groupby('Subject_ID').agg({\n",
    "        '1 - Volumetrics': lambda x: 'yes' if 'yes' in x.values else 'no',\n",
    "        '2 - Registration': lambda x: 'yes' if 'yes' in x.values else 'no',\n",
    "        '3 - DL': lambda x: 'yes' if 'yes' in x.values else 'no'\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(f\"Found {len(cta_subj)} unique subjects with CTA for {method}\")\n",
    "    \n",
    "    # Count failures for each individual column\n",
    "    volumetrics_count = len(cta_subj[cta_subj['1 - Volumetrics'] == 'yes']) if '1 - Volumetrics' in available_columns else 0\n",
    "    registration_count = len(cta_subj[cta_subj['2 - Registration'] == 'yes']) if '2 - Registration' in available_columns else 0\n",
    "    dl_count = len(cta_subj[cta_subj['3 - DL'] == 'yes']) if '3 - DL' in available_columns else 0\n",
    "    \n",
    "    # Count total failures (any failure in any column)\n",
    "    total_failures_count = len(cta_subj[cta_subj[available_columns].eq('yes').any(axis=1)]) if available_columns else 0\n",
    "    \n",
    "    # Count multiple failures (failures in 2 or more columns)\n",
    "    yes_counts_per_row = cta_subj[available_columns].eq('yes').sum(axis=1) if available_columns else pd.Series([0] * len(cta_subj))\n",
    "    multiple_failures_count = len(cta_subj[yes_counts_per_row >= 2])\n",
    "    \n",
    "    # Create results dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Method': [method],\n",
    "        'Total_Count': [total_count],\n",
    "        'Total_Failure_Count': [total_failures_count],\n",
    "        'Total_Failure_Rate': [total_failures_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Volumetrics_Count': [volumetrics_count],\n",
    "        'Volumetrics_Rate': [volumetrics_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Registration_Count': [registration_count],\n",
    "        'Registration_Rate': [registration_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'DL_Count': [dl_count],\n",
    "        'DL_Rate': [dl_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Multiple_Failures_Count': [multiple_failures_count],\n",
    "        'Multiple_Failures_Rate': [multiple_failures_count / total_count * 100 if total_count > 0 else 0]\n",
    "    })\n",
    "    \n",
    "    cta_results.append(df)\n",
    "\n",
    "# Combine all CTA results\n",
    "final_cta_results = pd.concat(cta_results, ignore_index=True)\n",
    "\n",
    "# Define column order\n",
    "column_order = [\n",
    "    \"Method\",\n",
    "    \"Total_Count\",\n",
    "    \"Total_Failure_Count\", \"Total_Failure_Rate\",\n",
    "    \"Volumetrics_Count\", \"Volumetrics_Rate\",\n",
    "    \"Registration_Count\", \"Registration_Rate\",\n",
    "    \"DL_Count\", \"DL_Rate\",\n",
    "    \"Multiple_Failures_Count\", \"Multiple_Failures_Rate\"\n",
    "]\n",
    "\n",
    "final_cta_results = final_cta_results[column_order]\n",
    "final_cta_results.to_csv('/Users/rushil/brain_extraction/results/qualitative/subj_lvl/Rushil_QC_cta_subj_results.csv', index=False)\n",
    "print(\"CTA subject-level results saved to CSV file\")\n",
    "final_cta_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c5d543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing artifact subject-level results for method: CTBET\n",
      "Found 12 artifact scans for CTBET\n",
      "Available failure columns for CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 11 unique subjects with artifact for CTBET\n",
      "Processing artifact subject-level results for method: Robust-CTBET\n",
      "Found 2 artifact scans for Robust-CTBET\n",
      "Available failure columns for Robust-CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 2 unique subjects with artifact for Robust-CTBET\n",
      "Processing artifact subject-level results for method: SynthStrip\n",
      "Found 47 artifact scans for SynthStrip\n",
      "Available failure columns for SynthStrip: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 40 unique subjects with artifact for SynthStrip\n",
      "Processing artifact subject-level results for method: HD-CTBET\n",
      "Found 14 artifact scans for HD-CTBET\n",
      "Available failure columns for HD-CTBET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 12 unique subjects with artifact for HD-CTBET\n",
      "Processing artifact subject-level results for method: CT_BET\n",
      "Found 20 artifact scans for CT_BET\n",
      "Available failure columns for CT_BET: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 20 unique subjects with artifact for CT_BET\n",
      "Processing artifact subject-level results for method: Brainchop\n",
      "Filtered out 7 files from brainchop\n",
      "Found 24 artifact scans for Brainchop\n",
      "Available failure columns for Brainchop: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 22 unique subjects with artifact for Brainchop\n",
      "Processing artifact subject-level results for method: CTbet_Docker\n",
      "Filtered out 7 files from dockerctbet\n",
      "Found 9 artifact scans for CTbet_Docker\n",
      "Available failure columns for CTbet_Docker: ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
      "Found 9 unique subjects with artifact for CTbet_Docker\n",
      "Artifact subject-level results saved to CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Subject_ID'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Date'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Time'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Subject_ID'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Date'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Time'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Subject_ID'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Date'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Time'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Subject_ID'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Date'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Time'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Subject_ID'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Date'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Time'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Subject_ID'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Date'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Time'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Subject_ID'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Date'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
      "/var/folders/mj/t4xh15z52jz47tfwjlckghkc0000gn/T/ipykernel_69501/2999215504.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  artifact_cases['Scan_Time'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[2])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Total_Count</th>\n",
       "      <th>Total_Failure_Count</th>\n",
       "      <th>Total_Failure_Rate</th>\n",
       "      <th>Volumetrics_Count</th>\n",
       "      <th>Volumetrics_Rate</th>\n",
       "      <th>Registration_Count</th>\n",
       "      <th>Registration_Rate</th>\n",
       "      <th>DL_Count</th>\n",
       "      <th>DL_Rate</th>\n",
       "      <th>Multiple_Failures_Count</th>\n",
       "      <th>Multiple_Failures_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTBET</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>17.391304</td>\n",
       "      <td>8</td>\n",
       "      <td>17.391304</td>\n",
       "      <td>6</td>\n",
       "      <td>13.043478</td>\n",
       "      <td>7</td>\n",
       "      <td>15.217391</td>\n",
       "      <td>7</td>\n",
       "      <td>15.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robust-CTBET</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>2</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>2</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>2</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>2</td>\n",
       "      <td>4.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynthStrip</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>58.695652</td>\n",
       "      <td>27</td>\n",
       "      <td>58.695652</td>\n",
       "      <td>15</td>\n",
       "      <td>32.608696</td>\n",
       "      <td>19</td>\n",
       "      <td>41.304348</td>\n",
       "      <td>20</td>\n",
       "      <td>43.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD-CTBET</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>6.521739</td>\n",
       "      <td>3</td>\n",
       "      <td>6.521739</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT_BET</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>62.962963</td>\n",
       "      <td>17</td>\n",
       "      <td>62.962963</td>\n",
       "      <td>12</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>11</td>\n",
       "      <td>40.740741</td>\n",
       "      <td>14</td>\n",
       "      <td>51.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brainchop</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>43.478261</td>\n",
       "      <td>20</td>\n",
       "      <td>43.478261</td>\n",
       "      <td>17</td>\n",
       "      <td>36.956522</td>\n",
       "      <td>6</td>\n",
       "      <td>13.043478</td>\n",
       "      <td>17</td>\n",
       "      <td>36.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTbet_Docker</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>6.521739</td>\n",
       "      <td>3</td>\n",
       "      <td>6.521739</td>\n",
       "      <td>2</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>1</td>\n",
       "      <td>2.173913</td>\n",
       "      <td>3</td>\n",
       "      <td>6.521739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Method  Total_Count  Total_Failure_Count  Total_Failure_Rate  \\\n",
       "0         CTBET           46                    8           17.391304   \n",
       "1  Robust-CTBET           46                    2            4.347826   \n",
       "2    SynthStrip           46                   27           58.695652   \n",
       "3      HD-CTBET           46                    3            6.521739   \n",
       "4        CT_BET           27                   17           62.962963   \n",
       "5     Brainchop           46                   20           43.478261   \n",
       "6  CTbet_Docker           46                    3            6.521739   \n",
       "\n",
       "   Volumetrics_Count  Volumetrics_Rate  Registration_Count  Registration_Rate  \\\n",
       "0                  8         17.391304                   6          13.043478   \n",
       "1                  2          4.347826                   2           4.347826   \n",
       "2                 27         58.695652                  15          32.608696   \n",
       "3                  3          6.521739                   0           0.000000   \n",
       "4                 17         62.962963                  12          44.444444   \n",
       "5                 20         43.478261                  17          36.956522   \n",
       "6                  3          6.521739                   2           4.347826   \n",
       "\n",
       "   DL_Count    DL_Rate  Multiple_Failures_Count  Multiple_Failures_Rate  \n",
       "0         7  15.217391                        7               15.217391  \n",
       "1         2   4.347826                        2                4.347826  \n",
       "2        19  41.304348                       20               43.478261  \n",
       "3         0   0.000000                        0                0.000000  \n",
       "4        11  40.740741                       14               51.851852  \n",
       "5         6  13.043478                       17               36.956522  \n",
       "6         1   2.173913                        3                6.521739  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Artifact Subject-Level Analysis\n",
    "artifact_results = []\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"Processing artifact subject-level results for method: {method}\")\n",
    "    # Read the CSV file with the new columns\n",
    "    csv_file = pd.read_csv(f'/Users/rushil/brain_extraction/data/qc/{method}/{method}_final_v2.csv')\n",
    "    \n",
    "    if method == 'Brainchop':\n",
    "        csv_file = csv_file[~csv_file['Filename'].isin(brainchop_exclude)]\n",
    "        print(f\"Filtered out {len(brainchop_exclude)} files from brainchop\")\n",
    "        \n",
    "    if method == 'CTbet_Docker':\n",
    "        csv_file = csv_file[~csv_file['Filename'].isin(dockerctbet_exclude)]\n",
    "        print(f\"Filtered out {len(dockerctbet_exclude)} files from dockerctbet\")    \n",
    "\n",
    "    # Apply exclusions based on filename prefixes\n",
    "    mask = ~csv_file['Filename'].str.startswith(exclude_prefixes)\n",
    "    csv_file = csv_file[mask]\n",
    "    \n",
    "    # Filter for artifact cases only\n",
    "    artifact_cases = csv_file[csv_file['artifact'] == 1]\n",
    "    print(f\"Found {len(artifact_cases)} artifact scans for {method}\")\n",
    "    \n",
    "    # Define the failure columns to check\n",
    "    failure_columns = ['1 - Volumetrics', '2 - Registration', '3 - DL']\n",
    "    available_columns = [col for col in failure_columns if col in artifact_cases.columns]\n",
    "    print(f\"Available failure columns for {method}: {available_columns}\")\n",
    "    \n",
    "    # Set total count based on method (subject-level counts)\n",
    "    if method != 'CT_BET':\n",
    "        total_count = 46  # Total subjects with artifact\n",
    "    else:\n",
    "        total_count = 27  # Total subjects with artifact for ctbet\n",
    "    \n",
    "    # Extract subject information and aggregate at subject level\n",
    "    artifact_cases['Subject_ID'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[0])\n",
    "    artifact_cases['Scan_Date'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[1])\n",
    "    artifact_cases['Scan_Time'] = artifact_cases['Filename'].apply(lambda x: x.split('_')[2])\n",
    "    \n",
    "    # Group by subject and aggregate (if any scan for a subject has failure, subject has failure)\n",
    "    artifact_subj = artifact_cases.groupby('Subject_ID').agg({\n",
    "        '1 - Volumetrics': lambda x: 'yes' if 'yes' in x.values else 'no',\n",
    "        '2 - Registration': lambda x: 'yes' if 'yes' in x.values else 'no',\n",
    "        '3 - DL': lambda x: 'yes' if 'yes' in x.values else 'no'\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(f\"Found {len(artifact_subj)} unique subjects with artifact for {method}\")\n",
    "    \n",
    "    # Count failures for each individual column\n",
    "    volumetrics_count = len(artifact_subj[artifact_subj['1 - Volumetrics'] == 'yes']) if '1 - Volumetrics' in available_columns else 0\n",
    "    registration_count = len(artifact_subj[artifact_subj['2 - Registration'] == 'yes']) if '2 - Registration' in available_columns else 0\n",
    "    dl_count = len(artifact_subj[artifact_subj['3 - DL'] == 'yes']) if '3 - DL' in available_columns else 0\n",
    "    \n",
    "    # Count total failures (any failure in any column)\n",
    "    total_failures_count = len(artifact_subj[artifact_subj[available_columns].eq('yes').any(axis=1)]) if available_columns else 0\n",
    "    \n",
    "    # Count multiple failures (failures in 2 or more columns)\n",
    "    yes_counts_per_row = artifact_subj[available_columns].eq('yes').sum(axis=1) if available_columns else pd.Series([0] * len(artifact_subj))\n",
    "    multiple_failures_count = len(artifact_subj[yes_counts_per_row >= 2])\n",
    "    \n",
    "    # Create results dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Method': [method],\n",
    "        'Total_Count': [total_count],\n",
    "        'Total_Failure_Count': [total_failures_count],\n",
    "        'Total_Failure_Rate': [total_failures_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Volumetrics_Count': [volumetrics_count],\n",
    "        'Volumetrics_Rate': [volumetrics_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Registration_Count': [registration_count],\n",
    "        'Registration_Rate': [registration_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'DL_Count': [dl_count],\n",
    "        'DL_Rate': [dl_count / total_count * 100 if total_count > 0 else 0],\n",
    "        'Multiple_Failures_Count': [multiple_failures_count],\n",
    "        'Multiple_Failures_Rate': [multiple_failures_count / total_count * 100 if total_count > 0 else 0]\n",
    "    })\n",
    "    \n",
    "    artifact_results.append(df)\n",
    "\n",
    "# Combine all artifact results\n",
    "final_artifact_results = pd.concat(artifact_results, ignore_index=True)\n",
    "\n",
    "# Define column order\n",
    "column_order = [\n",
    "    \"Method\",\n",
    "    \"Total_Count\",\n",
    "    \"Total_Failure_Count\", \"Total_Failure_Rate\",\n",
    "    \"Volumetrics_Count\", \"Volumetrics_Rate\",\n",
    "    \"Registration_Count\", \"Registration_Rate\",\n",
    "    \"DL_Count\", \"DL_Rate\",\n",
    "    \"Multiple_Failures_Count\", \"Multiple_Failures_Rate\"\n",
    "]\n",
    "\n",
    "final_artifact_results = final_artifact_results[column_order]\n",
    "final_artifact_results.to_csv('/Users/rushil/brain_extraction/results/qualitative/subj_lvl//Rushil_QC_artifact_subj_results.csv', index=False)\n",
    "print(\"Artifact subject-level results saved to CSV file\")\n",
    "final_artifact_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba108250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rush_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
